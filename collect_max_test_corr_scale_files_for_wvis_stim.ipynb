{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "import itertools\n",
    "from itertools import product\n",
    "import json\n",
    "\n",
    "from shutil import copyfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_units_with_lyr_for_cstr(expt_id, units_fname, cstr):\n",
    "    \n",
    "    cstr_lyr = pd.DataFrame()\n",
    "    #units_fname = os.path.join(units_df_basedir,expt_id + '_units_df.pkl')\n",
    "    units_df = pd.read_pickle(units_fname)\n",
    "    visp_units = units_df[units_df.ecephys_structure_acronym == cstr].index.values#[:5]\n",
    "    \n",
    "    lyrs_dir = '/Users/Ram/Dropbox/VC_NP_sklearn_copy/layer_est_from_Jung/'\n",
    "    lyr_fname = os.path.join(lyrs_dir,expt_id+'_layer.json')\n",
    "    try:\n",
    "        with open(lyr_fname) as datafile:\n",
    "            data = json.load(datafile)\n",
    "        lyr_df = pd.DataFrame(data.items(), index = data.keys())\n",
    "        cstr_lyr = lyr_df.loc[list(units_df[units_df.ecephys_structure_acronym ==cstr].peak_channel_id.values.astype(str))]\n",
    "        cstr_lyr.columns = ['peak_channel_id','layer']\n",
    "        cstr_lyr['unit_id'] = visp_units\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "    return units_df, cstr_lyr\n",
    "\n",
    "def get_scale_fnames_with_max_test_corr_wvis(prs_df_dir, expt_id, cstr, unit_id):\n",
    "    \n",
    "    separator = '_'\n",
    "    \n",
    "    cstr_scale = 1\n",
    "    stim_scale_list = [0.0, 0.01, 0.05, 0.1, 0.5, 1.0, 5.0, 10.0, 50.0]\n",
    "    tmp = pd.DataFrame()\n",
    "    for stim_scale in stim_scale_list:\n",
    "        \n",
    "        fname = separator.join([str(unit_id), 'fr_scale',str(cstr_scale), \\\n",
    "                                                  'stim_scale', str(stim_scale)]) + '.pkl'\n",
    "        \n",
    "        if os.path.isfile(os.path.join(prs_df_dir,fname)):\n",
    "            tmp_pd = pd.read_pickle(os.path.join(prs_df_dir,fname))\n",
    "            #tmp_pd.insert(loc=4,column='scale',value = scale)\n",
    "            tmp = pd.concat((tmp,tmp_pd),sort=False)\n",
    "    \n",
    "    max_ind = np.argmax(tmp.test_corr.values)\n",
    "    max_scale = tmp.iloc[max_ind]['stim_scale']\n",
    "    max_fname = separator.join([str(tmp.iloc[max_ind]['unit_id']), 'fr_scale',str(cstr_scale), \\\n",
    "                                                  'stim_scale', str(max_scale)]) + '.pkl' \n",
    "    #print(unit_id, max_scale, tmp.test_corr.values)\n",
    "    \n",
    "    return max_fname\n",
    "\n",
    "#    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ram' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-7636ace2f967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0munits_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcstr_lyr_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_units_with_lyr_for_cstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpt_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits_fname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mvisp_units\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munits_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0munits_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mecephys_structure_acronym\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ram' is not defined"
     ]
    }
   ],
   "source": [
    "units_df_basedir = '/Users/Ram/Dropbox/VC_NP_sklearn_copy/units_dfs'\n",
    "basedir = '/Users/Ram/Dropbox/VC_NP_sklearn_mod/sandbox_save_prs'\n",
    "\n",
    "expt_id_list = ['715093703']#['719161530']#['715093703'] #,'719161530'\n",
    "split_frac = 0.5\n",
    "\n",
    "stim_name = 'static_gratings'\n",
    "bin_dt = 0.005\n",
    "bin_start = 0.05#0.05\n",
    "bin_end = 0.15#0.15\n",
    "\n",
    "vis_cols = ['VISp']#['LGd','LP','VISam','VISpm','VISp','VISl','VISrl']\n",
    "for cstr in vis_cols:\n",
    "    for expt_id in expt_id_list:\n",
    "\n",
    "        units_fname = os.path.join(units_df_basedir,expt_id + '_units_df.pkl')\n",
    "        units_df, cstr_lyr_df = make_units_with_lyr_for_cstr(expt_id, units_fname, cstr)\n",
    "        \n",
    "        print(ram)\n",
    "        \n",
    "        visp_units = units_df[units_df.ecephys_structure_acronym == cstr].index.values\n",
    "\n",
    "        prs_df_dir =  os.path.join(basedir, expt_id, cstr, \\\n",
    "           stim_name, 't1_'+str(bin_start) + '_t2_'+str(bin_end) + '_dt_'+str(bin_dt))\n",
    "        \n",
    "        max_fname_list = []\n",
    "        for unit_id in visp_units:\n",
    "            max_fname = get_scale_fnames_with_max_test_corr_wvis(prs_df_dir, expt_id, cstr, unit_id)\n",
    "            max_fname_list.append(max_fname)\n",
    "        \n",
    "        src_dir = prs_df_dir\n",
    "        dst_dir = os.path.join(prs_df_dir,'max_test_corr')\n",
    "        if not os.path.exists(dst_dir):\n",
    "            os.makedirs(dst_dir)\n",
    "\n",
    "        for max_fname in max_fname_list:\n",
    "            src_fname = os.path.join(src_dir,max_fname)\n",
    "            dst_fname = os.path.join(dst_dir, max_fname)\n",
    "            copyfile(src_fname, dst_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#max_fname_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>peak_channel_id</th>\n",
       "      <th>layer</th>\n",
       "      <th>unit_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>850261846</th>\n",
       "      <td>850261846</td>\n",
       "      <td>2</td>\n",
       "      <td>950933960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850261814</th>\n",
       "      <td>850261814</td>\n",
       "      <td>2</td>\n",
       "      <td>950932445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850261838</th>\n",
       "      <td>850261838</td>\n",
       "      <td>2</td>\n",
       "      <td>950932696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850261822</th>\n",
       "      <td>850261822</td>\n",
       "      <td>2</td>\n",
       "      <td>950932563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850261822</th>\n",
       "      <td>850261822</td>\n",
       "      <td>2</td>\n",
       "      <td>950932578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850261718</th>\n",
       "      <td>850261718</td>\n",
       "      <td>6</td>\n",
       "      <td>950930375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850261724</th>\n",
       "      <td>850261724</td>\n",
       "      <td>6</td>\n",
       "      <td>950930522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850261726</th>\n",
       "      <td>850261726</td>\n",
       "      <td>6</td>\n",
       "      <td>950933732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850261720</th>\n",
       "      <td>850261720</td>\n",
       "      <td>6</td>\n",
       "      <td>950930437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850261708</th>\n",
       "      <td>850261708</td>\n",
       "      <td>6</td>\n",
       "      <td>950930145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          peak_channel_id  layer    unit_id\n",
       "850261846       850261846      2  950933960\n",
       "850261814       850261814      2  950932445\n",
       "850261838       850261838      2  950932696\n",
       "850261822       850261822      2  950932563\n",
       "850261822       850261822      2  950932578\n",
       "...                   ...    ...        ...\n",
       "850261718       850261718      6  950930375\n",
       "850261724       850261724      6  950930522\n",
       "850261726       850261726      6  950933732\n",
       "850261720       850261720      6  950930437\n",
       "850261708       850261708      6  950930145\n",
       "\n",
       "[62 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cstr_lyr_df.sort_values('layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.05, 0.1, 0.15, 0.2, 0.25, 0.3]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(round(ii,2)) for ii in 0.05 + np.arange(0.000,0.251,0.050)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuropixels_get_data_Nov2019_yaml",
   "language": "python",
   "name": "neuropixels_get_data_nov2019"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
